version: '3.1'
services:
  scheduler:
    environment:
      MF_DATASTORE_ROOT: s3://metaflow
      METAFLOW_DATASTORE_SYSROOT_S3: s3://metaflow
      METAFLOW_DATATOOLS_SYSROOT_S3: s3://metaflow/data
      LOGLEVEL: "DEBUG"
      METAFLOW_SERVICE_URL: "http://host.docker.internal:8081"
      METAFLOW_DEFAULT_DATASTORE: s3
      METAFLOW_DEFAULT_METADATA: "service"
      MF_METADATA_DB_NAME: postgres
      MF_METADATA_DB_PORT: 5432
      MF_METADATA_DB_PSWD: postgres
      MF_METADATA_DB_USER: postgres
      MF_METADATA_DB_HOST: host.docker.internal
      DB_SCHEMA_NAME: public
      METAFLOW_S3_ENDPOINT_URL: "s3://host.docker.internal:9000"
      USERNAME: 'astro'
  minio:
    image: quay.io/minio/minio
    command:
    - server 
    - /data 
    - --console-address 
    - ":9001"
    ports:
    - 9000:9000
    - 9001:9001
    volumes:
    - ${PWD}/include/minio/data:/data
    extra_hosts:
    - "host.docker.internal:host-gateway"
  metaflow-metadata-service:
    image: netflixoss/metaflow_metadata_service:latest
    #public.ecr.aws/outerbounds/metaflow_metadata_service:2.3.6-7-gd9006dc-obp
    # working_dir:  /src
    command: ["/opt/latest/bin/python3", "-m", "services.metadata_service.server" ]
    environment:
      PYTHONPATH: "${PYTHONPATH}:/src"
      MF_METADATA_DB_NAME: postgres
      MF_METADATA_DB_PORT: 5432
      MF_METADATA_DB_PSWD: postgres
      MF_METADATA_DB_USER: postgres
      MF_METADATA_DB_HOST: host.docker.internal
      DB_SCHEMA_NAME: public
      MF_METADATA_PORT: 8081
      METAFLOW_S3_ENDPOINT_URL: "s3://host.docker.internal:9000"
    env_file: .env
    ports:
    - 8081:8081
    # - 8082:8082
  metaflow-ui:
    image: public.ecr.aws/outerbounds/metaflow_ui:1.2.6
    environment:
      METAFLOW_SERVICE: "http://host.docker.internal:8083"
    ports:
    - 3000:3000
  metaflow-ui-backend:
    image: public.ecr.aws/outerbounds/metaflow_metadata_service:2.3.6-7-gd9006dc-obp
    # working_dir:  /src
    command: ["/opt/latest/bin/python3", "-m", "services.ui_backend_service.ui_server" ]
    environment:
      PYTHONPATH: "${PYTHONPATH}:/src"
      UI_ENABLED: "1"
      PATH_PREFIX: "/api"
      MF_DATASTORE_ROOT: metaflow
      METAFLOW_DATASTORE_SYSROOT_S3: metaflow
      LOGLEVEL: "DEBUG"
      METAFLOW_SERVICE_URL: "http://host.docker.internal:8081"
      METAFLOW_DEFAULT_DATASTORE: s3
      METAFLOW_DEFAULT_METADATA: "service"
      MF_METADATA_DB_NAME: postgres
      MF_METADATA_DB_PORT: 5432
      MF_METADATA_DB_PSWD: postgres
      MF_METADATA_DB_USER: postgres
      MF_METADATA_DB_HOST: host.docker.internal
      DB_SCHEMA_NAME: public
      METAFLOW_S3_ENDPOINT_URL: "s3://host.docker.internal:9000"
    env_file: .env
    ports:
    - 8083:8083
  migration:
    image: public.ecr.aws/outerbounds/metaflow_metadata_service:2.3.6-7-gd9006dc-obp
    working_dir:  /src
    command: ["/opt/latest/bin/python3", "run_goose.py"]
    build:
      context: .
      dockerfile: Dockerfile
    volumes:
      - ./services:/root/services
    environment:
      MF_METADATA_DB_NAME: postgres
      MF_METADATA_DB_PORT: 5432
      MF_METADATA_DB_PSWD: postgres
      MF_METADATA_DB_USER: postgres
      MF_METADATA_DB_HOST: host.docker.internal
      DB_SCHEMA_NAME: public
      MF_METADATA_PORT: 8081
      MF_METADATA_HOST: host.docker.internal
      # - MF_MIGRATION_ENDPOINTS_ENABLED=1
      # - MF_MIGRATION_PORT=${MF_MIGRATION_PORT:-8082}
    depends_on:
      - postgres